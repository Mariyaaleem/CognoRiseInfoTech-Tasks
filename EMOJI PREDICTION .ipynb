{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEYYwgiD6hLdyKh5OJqscg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFKCaIcIHZCE","executionInfo":{"status":"ok","timestamp":1716747608419,"user_tz":-330,"elapsed":28390,"user":{"displayName":"Mariya Aleem","userId":"01301829714474258659"}},"outputId":"efa966fa-ae11-4365-b77d-ae156ae43e32"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","# Load the datasets\n","train_df = pd.read_csv('Train.csv')\n","test_df = pd.read_csv('Test.csv')\n","mapping_df = pd.read_csv('Mapping.csv')\n","OutputFormats_df\n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Define a function to clean the text\n","def clean_text(text):\n","    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n","    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n","    text = re.sub(r'#\\w+', '', text)     # Remove hashtags\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n","    text = text.lower()                  # Convert to lowercase\n","    return text\n","\n","# Apply the cleaning function to the datasets\n","train_df['cleaned_text'] = train_df['TEXT'].apply(clean_text)\n","test_df['cleaned_text'] = test_df['TEXT'].apply(clean_text)\n","\n","# Tokenize the text\n","train_df['tokens'] = train_df['cleaned_text'].apply(word_tokenize)\n","test_df['tokens'] = test_df['cleaned_text'].apply(word_tokenize)\n","\n","# Remove stopwords\n","stop_words = set(stopwords.words('english'))\n","train_df['tokens'] = train_df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n","test_df['tokens'] = test_df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n","\n","# Join tokens back into strings for TF-IDF Vectorizer\n","train_df['cleaned_text'] = train_df['tokens'].apply(lambda x: ' '.join(x))\n","test_df['cleaned_text'] = test_df['tokens'].apply(lambda x: ' '.join(x))\n","\n","# Create TF-IDF features\n","tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n","X_train = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])\n","X_test = tfidf_vectorizer.transform(test_df['cleaned_text'])\n","\n","# Encode the labels\n","number_to_emoticon = dict(zip(mapping_df['number'], mapping_df['emoticons']))\n","train_df['emoticon'] = train_df['Label'].map(number_to_emoticon)\n","label_encoder = LabelEncoder()\n","train_df['emoji_label'] = label_encoder.fit_transform(train_df['emoticon'])\n","\n","# Split the training data into training and validation sets\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, train_df['emoji_label'], test_size=0.2, random_state=42)\n"]},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","\n","# Apply SMOTE to balance the dataset\n","smote = SMOTE(random_state=42)\n","X_train_res, y_train_res = smote.fit_resample(X_train_split, y_train_split)\n"],"metadata":{"id":"YuwT-DajHlJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n","from sklearn.metrics import classification_report\n","import time\n","\n","# Define the adjusted parameter grid for RandomForest\n","param_dist = {\n","    'n_estimators': [50, 100],  # Reduced number of estimators\n","    'max_depth': [10, 20],      # Reduced max depth\n","    'min_samples_split': [2, 5]\n","}\n","\n","# Initialize RandomForestClassifier\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","# Use StratifiedKFold for better class balance in folds\n","stratified_kfold = StratifiedKFold(n_splits=3)\n","\n","# RandomizedSearchCV for hyperparameter tuning\n","random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=5, cv=stratified_kfold, n_jobs=-1, verbose=2, random_state=42)\n","\n","# Start timer\n","start = time.time()\n","\n","random_search.fit(X_train_res, y_train_res)\n","\n","# End timer\n","end = time.time()\n","print(f\"RandomizedSearchCV took {end - start:.2f} seconds\")\n","\n","# Get the best estimator\n","best_rf_model = random_search.best_estimator_\n","\n","# Predict on the validation set\n","y_val_pred = best_rf_model.predict(X_val)\n","\n","# Evaluate the model\n","print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlIpTArqIi5B","executionInfo":{"status":"ok","timestamp":1716747768038,"user_tz":-330,"elapsed":118473,"user":{"displayName":"Mariya Aleem","userId":"01301829714474258659"}},"outputId":"00fb2204-2875-47ed-ba65-9760fd734fcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 5 candidates, totalling 15 fits\n","RandomizedSearchCV took 117.78 seconds\n","              precision    recall  f1-score   support\n","\n","           ‚òÄ       0.17      0.58      0.26       370\n","           ‚ú®       0.27      0.12      0.17       644\n","           ‚ù§       0.38      0.16      0.23      3049\n","          üá∫üá∏       0.38      0.41      0.39       509\n","           üéÑ       0.43      0.70      0.53       387\n","           üíï       0.13      0.14      0.13       728\n","           üíô       0.14      0.10      0.12       466\n","           üíú       0.11      0.04      0.06       358\n","           üíØ       0.08      0.14      0.10       356\n","           üì∑       0.06      0.05      0.05       431\n","           üì∏       0.06      0.40      0.10       531\n","           üî•       0.35      0.32      0.33       875\n","           üòÅ       0.09      0.04      0.05       355\n","           üòÇ       0.32      0.20      0.24      1384\n","           üòâ       0.05      0.06      0.06       372\n","           üòä       0.07      0.03      0.04       531\n","           üòç       0.25      0.08      0.12      1408\n","           üòé       0.28      0.06      0.10       587\n","           üòò       0.10      0.21      0.13       377\n","           üòú       0.04      0.05      0.04       282\n","\n","    accuracy                           0.18     14000\n","   macro avg       0.19      0.19      0.16     14000\n","weighted avg       0.25      0.18      0.18     14000\n","\n"]}]},{"cell_type":"code","source":["def predict_emoji(text, model, vectorizer, encoder):\n","    cleaned_text = clean_text(text)\n","    tokens = word_tokenize(cleaned_text)\n","    tokens = [word for word in tokens if word not in stop_words]\n","    text_features = vectorizer.transform([' '.join(tokens)])\n","    emoji_label = model.predict(text_features)[0]\n","    emoji = encoder.inverse_transform([emoji_label])[0]\n","    return emoji\n","\n","# Test the function with new inputs\n","new_texts = [\n","    \"I love spending time with my family! \",\n","    \"This is so frustrating \",\n","    \"Can't wait for the weekend! \",\n","    \"Just finished a great workout \"\n","]\n","\n","for text in new_texts:\n","    print(f\"Text: {text}\")\n","    print(f\"Predicted Emoji: {predict_emoji(text, best_rf_model, tfidf_vectorizer, label_encoder)}\")\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eyc99nZZIrIU","executionInfo":{"status":"ok","timestamp":1716747984630,"user_tz":-330,"elapsed":415,"user":{"displayName":"Mariya Aleem","userId":"01301829714474258659"}},"outputId":"e7321edf-c185-46d7-f68d-c9135a5d25a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text: I love spending time with my family! \n","Predicted Emoji: ‚ù§\n","\n","Text: This is so frustrating \n","Predicted Emoji: üì∏\n","\n","Text: Can't wait for the weekend! \n","Predicted Emoji: üòâ\n","\n","Text: Just finished a great workout \n","Predicted Emoji: üòä\n","\n"]}]}]}